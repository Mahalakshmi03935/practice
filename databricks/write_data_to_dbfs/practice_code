

data = [("Raja", 21), ("Maha", 22), ("Lakshmi",23)]


df = spark.createDataFrame(data, ["Name", "Age"])

output_path = "dbfs:/FileStore/shared_uploads/rajamahalakshmi.b@diggibyte.com/data.csv"

# Write DataFrame to CSV
df.write.csv("dbfs:/FileStore/shared_uploads/rajamahalakshmi.b@diggibyte.com/data.csv", header=True)




# COMMAND ----------

df.show()

# COMMAND ----------

#write parquet file

# COMMAND ----------

data = [("Raja", 21, "America"), ("Maha", 22, "Switzerland"), ("Lakshmi",23, "Australia")]


df = spark.createDataFrame(data, ["Name", "Age" , "Place"])

output_path = "dbfs:/FileStore/shared_uploads/rajamahalakshmi.b@diggibyte.com/Iris11.parquet"

# COMMAND ----------

df.write.parquet( "dbfs:/FileStore/shared_uploads/rajamahalakshmi.b@diggibyte.com/Iris11.parquet")

# COMMAND ----------

df.show()

# COMMAND ----------

#writing json file

# COMMAND ----------

input_path = "dbfs:/FileStore/shared_uploads/rajamahalakshmi.b@diggibyte.com/example_1.json"

# Read JSON file into DataFrame
df = spark.read.json("dbfs:/FileStore/shared_uploads/rajamahalakshmi.b@diggibyte.com/example_1.json")

# Show the DataFrame
df.show()

